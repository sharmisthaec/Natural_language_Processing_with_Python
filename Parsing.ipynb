{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Chetana\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Free Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'is', 'very', 'interesting']\n",
      "[('NLP', 'NNP'), ('is', 'VBZ'), ('very', 'RB'), ('interesting', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det NP | Adj NP | Adj | N | Adv NP\n",
    "    VP -> V NP  \n",
    "    Det -> \"a\" | \"an\" | \"the\" \n",
    "    V -> \"is\"\n",
    "    Adj -> \"interesting\" | \"very\"\n",
    "    N -> \"NLP\" | \"subject\"\n",
    "    Adv -> \"very\"\n",
    "\"\"\")\n",
    "\n",
    "statement = \"NLP is very interesting\"\n",
    "sentence = word_tokenize(statement)\n",
    "print(sentence)\n",
    "print(nltk.pos_tag(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (N NLP)) (VP (V is) (NP (Adj very) (NP (Adj interesting)))))\n",
      "(S (NP (N NLP)) (VP (V is) (NP (Adv very) (NP (Adj interesting)))))\n"
     ]
    }
   ],
   "source": [
    "# Recursive descent parser is a kind of top-down parser \n",
    "# built from a set of mutually recursive procedures \n",
    "# where each such procedure implements one of the nonterminals of the grammar. \n",
    "rd_parser = nltk.RecursiveDescentParser(grammar)\n",
    "total_trees = 0\n",
    "for tree in rd_parser.parse(sentence):\n",
    "    total_trees = total_trees+1\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguious grammar\n"
     ]
    }
   ],
   "source": [
    "if total_trees > 1 :\n",
    "    print(\"Ambiguious grammar\")\n",
    "else:\n",
    "    print(\"Unambiguious grammar\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('girl', 'NN'), ('is', 'VBZ'), ('laughing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "# When a chart parser begins parsing a text, it creates a new (empty) chart, spanning the text. \n",
    "# It then incrementally adds new edges to the chart.  \n",
    "# A set of \"chart rules\" specifies the conditions under which new edges should be added to the chart.\n",
    "# Once the chart reaches a stage where none of the chart rules adds any new edges, parsing is complete.\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP \n",
    "    VP -> V NP | Aux VP | V\n",
    "    NP -> Det NP | N | Adj NP | Adj\n",
    "    N -> \"girl\" | \"boy\"\n",
    "    Det -> \"The\"\n",
    "    Aux -> \"is\"\n",
    "    V -> \"laughing\" | \"playing\" \n",
    "    Adj -> \"laughing\" | \"well\"\n",
    "\"\"\")\n",
    "statement = nltk.word_tokenize(\"The girl is laughing\")\n",
    "print(nltk.pos_tag(statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (Det The) (NP (N girl))) (VP (Aux is) (VP (V laughing))))\n"
     ]
    }
   ],
   "source": [
    "total_trees = 0\n",
    "rd_parser = nltk.ChartParser(grammar1)\n",
    "for tree in rd_parser.parse(statement):\n",
    "    total_trees = total_trees + 1\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unambiguious grammar\n"
     ]
    }
   ],
   "source": [
    "if total_trees > 1 :\n",
    "    print(\"Ambiguious grammar\")\n",
    "else:\n",
    "    print(\"Unambiguious grammar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('can', 'MD'), ('can', 'MD'), ('hold', 'VB'), ('a', 'DT'), ('can', 'MD'), ('of', 'IN'), ('water', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP \n",
    "    VP -> V NP | Aux VP | V NP PP | V\n",
    "    PP -> P NP\n",
    "    NP -> Det NP | N | Adj NP | Adj | Det N PP\n",
    "    N -> \"girl\" | \"boy\" | \"Omkar\" | \"can\" | \"hold\" | \"water\"\n",
    "    Det -> \"The\" | \"a\" | \"the\"\n",
    "    Aux -> \"is\" | \"can\"\n",
    "    P -> \"of\" | \"with\"\n",
    "    V -> \"laughing\" | \"playing\" | \"can\" | \"hold\" | \"water\"\n",
    "    Adj -> \"laughing\" | \"well\"\n",
    "\"\"\")\n",
    "statement = nltk.word_tokenize(\"The can can hold a can of water\")\n",
    "print(nltk.pos_tag(statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Det The) (NP (N can)))\n",
      "  (VP\n",
      "    (Aux can)\n",
      "    (VP\n",
      "      (V hold)\n",
      "      (NP (Det a) (NP (N can)))\n",
      "      (PP (P of) (NP (N water))))))\n",
      "(S\n",
      "  (NP (Det The) (NP (N can)))\n",
      "  (VP\n",
      "    (Aux can)\n",
      "    (VP (V hold) (NP (Det a) (N can) (PP (P of) (NP (N water)))))))\n"
     ]
    }
   ],
   "source": [
    "tree_count = 0\n",
    "chart_parser = nltk.ChartParser(grammar1)\n",
    "for tree in chart_parser.parse(statement):\n",
    "    tree_count = tree_count+1\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguos Sentence\n"
     ]
    }
   ],
   "source": [
    "if tree_count > 1 :\n",
    "    print(\"Ambiguos Sentence\")\n",
    "else :\n",
    "    print(\"Unambiguos Sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilitic Context Free Grammar (PCFG)\n",
    "A PCFG consists of a start state and a set of productions with probabilities. The set of terminals and nonterminals is implicitly specified by the productions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside Chart Parser"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Parser for PCFG grammars that tries edges in descending order of the inside \n",
    "# probabilities of their trees. The “inside probability” of a tree is simply the probability of the \n",
    "# entire tree, ignoring its context\n",
    "\n",
    "from nltk.grammar import toy_pcfg1\n",
    "from nltk.parse import pchart\n",
    "import time\n",
    "demos = [('John saw the man with the telescope' , toy_pcfg1)]\n",
    "\n",
    "sent, grammar = demos[0]\n",
    "\n",
    "# Tokenize the sentence.\n",
    "tokens = word_tokenize(sent)\n",
    "print(tokens)\n",
    "print(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The grammar must be probabilistic PCFG",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-b84cbb959bd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpchart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInsideChartParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n sentence: %s\\n parser: %s\\n grammar_rules: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\parse\\pchart.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, grammar, beam_size, trace)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCFG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The grammar must be probabilistic PCFG\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grammar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The grammar must be probabilistic PCFG"
     ]
    }
   ],
   "source": [
    "parser = pchart.InsideChartParser(grammar)\n",
    "times=[]\n",
    "print('\\n sentence: %s\\n parser: %s\\n grammar_rules: %s' % (sent,parser,grammar))\n",
    "parser.trace(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |. . . . . . [-]| [6:7] 'telescope'                [1.0]\n",
      "  |. . . . . [-] .| [5:6] 'the'                      [1.0]\n",
      "  |. . . . [-] . .| [4:5] 'with'                     [1.0]\n",
      "  |. . . [-] . . .| [3:4] 'man'                      [1.0]\n",
      "  |. . [-] . . . .| [2:3] 'the'                      [1.0]\n",
      "  |. [-] . . . . .| [1:2] 'saw'                      [1.0]\n",
      "  |[-] . . . . . .| [0:1] 'John'                     [1.0]\n",
      "  |. . [-] . . . .| [2:3] Det -> 'the' *             [0.8]\n",
      "  |. . > . . . . .| [2:2] Det -> * 'the'             [0.8]\n",
      "  |. . . . . [-] .| [5:6] Det -> 'the' *             [0.8]\n",
      "  |. . . . . > . .| [5:5] Det -> * 'the'             [0.8]\n",
      "  |. [-] . . . . .| [1:2] V  -> 'saw' *              [0.65]\n",
      "  |. > . . . . . .| [1:1] VP -> * V NP               [0.7]\n",
      "  |. > . . . . . .| [1:1] V  -> * 'saw'              [0.65]\n",
      "  |. . . . [-] . .| [4:5] P  -> 'with' *             [0.61]\n",
      "  |. . . . > . . .| [4:4] PP -> * P NP               [1.0]\n",
      "  |. . . . [-> . .| [4:5] PP -> P * NP               [0.61]\n",
      "  |. . . . > . . .| [4:4] P  -> * 'with'             [0.61]\n",
      "  |. . . . . > . .| [5:5] NP -> * Det N              [0.5]\n",
      "  |. . > . . . . .| [2:2] NP -> * Det N              [0.5]\n",
      "  |. . . [-] . . .| [3:4] N  -> 'man' *              [0.5]\n",
      "  |. . . > . . . .| [3:3] N  -> * 'man'              [0.5]\n",
      "  |. . . . . . [-]| [6:7] N  -> 'telescope' *        [0.5]\n",
      "  |. . . . . . > .| [6:6] N  -> * 'telescope'        [0.5]\n",
      "  |. [-> . . . . .| [1:2] VP -> V * NP               [0.45499999999999996]\n",
      "  |. . . . . [-> .| [5:6] NP -> Det * N              [0.4]\n",
      "  |. . [-> . . . .| [2:3] NP -> Det * N              [0.4]\n",
      "  |. . . . . [---]| [5:7] NP -> Det N *              [0.2]\n",
      "  |. . . . . > . .| [5:5] S  -> * NP VP              [1.0]\n",
      "  |. . . . . > . .| [5:5] NP -> * NP PP              [0.25]\n",
      "  |. . . . . [--->| [5:7] S  -> NP * VP              [0.2]\n",
      "  |. . [---] . . .| [2:4] NP -> Det N *              [0.2]\n",
      "  |. . > . . . . .| [2:2] S  -> * NP VP              [1.0]\n",
      "  |. . > . . . . .| [2:2] NP -> * NP PP              [0.25]\n",
      "  |. . [---> . . .| [2:4] S  -> NP * VP              [0.2]\n",
      "  |. > . . . . . .| [1:1] VP -> * V                  [0.2]\n",
      "  |. [-] . . . . .| [1:2] VP -> V *                  [0.13]\n",
      "  |. . . . [-----]| [4:7] PP -> P NP *               [0.122]\n",
      "  |. > . . . . . .| [1:1] VP -> * VP PP              [0.1]\n",
      "  |[-] . . . . . .| [0:1] NP -> 'John' *             [0.1]\n",
      "  |> . . . . . . .| [0:0] S  -> * NP VP              [1.0]\n",
      "  |> . . . . . . .| [0:0] NP -> * NP PP              [0.25]\n",
      "  |[-> . . . . . .| [0:1] S  -> NP * VP              [0.1]\n",
      "  |> . . . . . . .| [0:0] NP -> * 'John'             [0.1]\n",
      "  |. [-----] . . .| [1:4] VP -> V NP *               [0.091]\n",
      "  |. . [---> . . .| [2:4] NP -> NP * PP              [0.05]\n",
      "  |. . . . . [--->| [5:7] NP -> NP * PP              [0.05]\n",
      "  |[-> . . . . . .| [0:1] NP -> NP * PP              [0.025]\n",
      "  |[---] . . . . .| [0:2] S  -> NP VP *              [0.013000000000000001]\n",
      "  |. [-> . . . . .| [1:2] VP -> VP * PP              [0.013000000000000001]\n",
      "  |[-------] . . .| [0:4] S  -> NP VP *              [0.0091]\n",
      "  |. [-----> . . .| [1:4] VP -> VP * PP              [0.0091]\n",
      "  |. . [---------]| [2:7] NP -> NP PP *              [0.0061]\n",
      "  |. . [--------->| [2:7] S  -> NP * VP              [0.0061]\n",
      "  |. [-----------]| [1:7] VP -> V NP *               [0.0027754999999999998]\n",
      "  |. . [--------->| [2:7] NP -> NP * PP              [0.001525]\n",
      "  |. [-----------]| [1:7] VP -> VP PP *              [0.0011102]\n",
      "  |[=============]| [0:7] S  -> NP VP *              [0.00027755]\n",
      "  |. [----------->| [1:7] VP -> VP * PP              [0.00027755]\n",
      "  |[=============]| [0:7] S  -> NP VP *              [0.00011102]\n",
      "  |. [----------->| [1:7] VP -> VP * PP              [0.00011102]\n",
      "the time required by the Inside Chart parser  [0.00997304916381836] \n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "parses = parser.parse_all(tokens)\n",
    "times.append(time.time()-t)\n",
    "print(\"the time required by the Inside Chart parser  %s \"%(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP John)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Det the) (N man))\n",
      "      (PP (P with) (NP (Det the) (N telescope)))))) (p=0.00027755)\n"
     ]
    }
   ],
   "source": [
    "for parse in parses:\n",
    "    print(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'saw', 'the', 'man', 'with', 'the', 'telescope']\n",
      "[('John', 'NNP'), ('saw', 'VBD'), ('the', 'DT'), ('man', 'NN'), ('with', 'IN'), ('the', 'DT'), ('telescope', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# PCFG parser that uses dynamic programming to find the single most likely parse \n",
    "# for a text. The ViterbiParser parser parses texts by filling in a “most likely constituent table”.\n",
    "# This table records the most probable tree representation for any given span and node value.\n",
    "\n",
    "from nltk import ViterbiParser\n",
    "demos = [('John saw the man with the telescope' , toy_pcfg1)]\n",
    "\n",
    "sent, grammar = demos[0]\n",
    "\n",
    "# Tokenize the sentence.\n",
    "tokens = word_tokenize(sent)\n",
    "print(tokens)\n",
    "print(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sentence: John saw the man with the telescope\n",
      " parser: <ViterbiParser for <Grammar with 16 productions>>\n",
      " grammar_rules: Grammar with 16 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> Det NP\n",
      "    NP -> Adj NP\n",
      "    NP -> Adj\n",
      "    NP -> N\n",
      "    NP -> Adv NP\n",
      "    VP -> V NP\n",
      "    Det -> 'a'\n",
      "    Det -> 'an'\n",
      "    Det -> 'the'\n",
      "    V -> 'is'\n",
      "    Adj -> 'interesting'\n",
      "    Adj -> 'very'\n",
      "    N -> 'NLP'\n",
      "    N -> 'subject'\n",
      "    Adv -> 'very'\n"
     ]
    }
   ],
   "source": [
    "parser = ViterbiParser(grammar)\n",
    "times=[]\n",
    "print('\\n sentence: %s\\n parser: %s\\n grammar_rules: %s' % (sent,parser,grammar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting tokens into the most likely constituents table...\n",
      "Finding the most likely constituents spanning 1 text elements...\n",
      "Finding the most likely constituents spanning 2 text elements...\n",
      "Finding the most likely constituents spanning 3 text elements...\n",
      "Finding the most likely constituents spanning 4 text elements...\n",
      "Finding the most likely constituents spanning 5 text elements...\n",
      "Finding the most likely constituents spanning 6 text elements...\n",
      "Finding the most likely constituents spanning 7 text elements...\n",
      "the time required by the Viterbi parser  [0.0069789886474609375] \n"
     ]
    }
   ],
   "source": [
    "parser.trace(1)\n",
    "t = time.time()\n",
    "parses = parser.parse_all(tokens)\n",
    "times.append(time.time()-t)\n",
    "print(\"the time required by the Viterbi parser  %s \"%(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP John)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Det the) (N man))\n",
      "      (PP (P with) (NP (Det the) (N telescope)))))) (p=0.00027755)\n"
     ]
    }
   ],
   "source": [
    "for parse in parses:\n",
    "    print(parse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
